# Optimizers-Learning-rates-and-Activation-function-analysis
Analysis of performance of various optimizers like(SGD,Adagrad,Adadelta,RMSprop &amp; Adam ), various learning rates like(1,0.1,0.01,0.001,0.0001) and activation functions like(LeakyReLU , ELU , PReLU , sigmoid , tanh and relu) on mnist dataset.
